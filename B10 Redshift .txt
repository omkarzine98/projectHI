#AWS

AWS Athena : 

AWS Glue : 
1.Data Catlog 


AWS Redshift:
Cloud DWH 
Server based
cluster 
load 
Hive 


cluster : Node  ? 

awsuser
Awspassword1

jdbc:redshift://redshift-cluster-1.cjrbxdksn54c.ap-south-1.redshift.amazonaws.com:5439/dev



==============

from pyspark.sql import SparkSession


spark=SparkSession.builder.master("local").appName("RDBMSProcess").getOrCreate()

#Read

df=spark.read.format("JDBC").option("url","jdbc:redshift://redshift-cluster-1.cjrbxdksn54c.ap-south-1.redshift.amazonaws.com:5439/dev")\
    .option("user","awsuser").option("password","Awspassword1").option("driver","com.amazon.redshift.jdbc42.Driver")\
    .option("dbtable","event").load()



df1=df.filter(df['catid'] == 6)

df1.show()

df1.write.format("JDBC").option("url","jdbc:redshift://redshift-cluster-1.cjrbxdksn54c.ap-south-1.redshift.amazonaws.com:5439/dev")\
    .option("user","awsuser").option("password","Awspassword1").option("driver","com.amazon.redshift.jdbc42.Driver")\
    .option("dbtable","eventnew").save()


#Stop
spark.stop()
 